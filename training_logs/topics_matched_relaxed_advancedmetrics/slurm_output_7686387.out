-----TRAINING PARAMETERS-----
Model version: QA
Labels: relaxed
Setting: matched
Test scenario: 0
Auxilary tasks: ['TOPICS']
Auxilary task probing: False
PyTorch device: cuda
Max epochs: 5
Patience: 3
Learning rates: [5e-05, 2e-05]
Batch size: 8
Results directory: ./mtl_results
Progress bar: False
Advanced metrics: True
Pretrain: False
-----------------------------
Loading datasets..
Pre-loading annotations for most important word in answer
[nltk_data] Downloading package wordnet to /home/lcur0659/nltk_data...
Pre-loading annotations for topics in answer
[nltk_data]   Package wordnet is already up-to-date!
After removing empty topics, we have 12068; 3964; and 4075 samples for (respectively) train, dev, test sets for topic aux task
Loading model..
Model loaded
Datasets loaded for training
Start training on datasets:  ('Circa', 'TOPICS')
Starting training..
Epoch 0:
Dev results:
{'TOPICS': {'loss': 2.8454, 'accuracy': 0.017}, 'Circa': {'loss': 1.994, 'accuracy': 0.0203}, 'time': {'elapsed_time': '0:01:54.815820'}}
Epoch 1:
Train results:
{'TOPICS': {'loss': 1.6547, 'accuracy': 0.485}, 'Circa': {'loss': 0.5809, 'accuracy': 0.7656}, 'time': {'elapsed_time': '0:18:24.996377'}}
Dev results:
{'Circa': {'loss': 0.4482, 'accuracy': 0.8286}, 'TOPICS': {'loss': 0.9661, 'accuracy': 0.7294}, 'time': {'elapsed_time': '0:02:01.755564'}}
Saving new best model..
New best model saved
---
Epoch 2:
Train results:
{'Circa': {'loss': 0.3523, 'accuracy': 0.8695}, 'TOPICS': {'loss': 0.7366, 'accuracy': 0.7958}, 'time': {'elapsed_time': '0:18:21.579869'}}
Dev results:
{'Circa': {'loss': 0.4203, 'accuracy': 0.8439}, 'TOPICS': {'loss': 0.6947, 'accuracy': 0.8092}, 'time': {'elapsed_time': '0:02:01.715081'}}
Saving new best model..
New best model saved
---
Epoch 3:
Train results:
{'TOPICS': {'loss': 0.4718, 'accuracy': 0.873}, 'Circa': {'loss': 0.2367, 'accuracy': 0.9189}, 'time': {'elapsed_time': '0:18:20.648772'}}
Dev results:
{'Circa': {'loss': 0.4448, 'accuracy': 0.858}, 'TOPICS': {'loss': 0.6336, 'accuracy': 0.841}, 'time': {'elapsed_time': '0:02:01.603559'}}
Saving new best model..
New best model saved
---
Epoch 4:
Train results:
{'TOPICS': {'loss': 0.3191, 'accuracy': 0.9114}, 'Circa': {'loss': 0.1598, 'accuracy': 0.9466}, 'time': {'elapsed_time': '0:18:19.310222'}}
Dev results:
{'TOPICS': {'loss': 0.5831, 'accuracy': 0.8602}, 'Circa': {'loss': 0.4455, 'accuracy': 0.8669}, 'time': {'elapsed_time': '0:02:01.568704'}}
Saving new best model..
New best model saved
---
Epoch 5:
Train results:
{'TOPICS': {'loss': 0.2298, 'accuracy': 0.9396}, 'Circa': {'loss': 0.1162, 'accuracy': 0.9606}, 'time': {'elapsed_time': '0:18:18.125783'}}
Dev results:
{'Circa': {'loss': 0.5102, 'accuracy': 0.8633}, 'TOPICS': {'loss': 0.6078, 'accuracy': 0.8538}, 'time': {'elapsed_time': '0:02:01.647203'}}
---
Training finished
Loading best model..
Best model loaded
Starting testing..
{'Circa': {'Yes': 0, 'No': 1, 'In the middle, neither yes nor no': 2, 'Yes, subject to some conditions': 3}, 'TOPICS': ['amount', 'group', 'attribute', 'abstraction', 'quantity', 'human_action', 'event', 'whole', 'artifact', 'unit', 'living_thing', 'knowledge', 'organism', 'physical_entity', 'being', 'physical_object', 'communication', 'cause']}
Test results:
{'Circa': {'loss': 0.4465, 'accuracy': 0.8657, 'confusion_matrix': [[2744, 259, 10, 51], [328, 1991, 12, 11], [42, 40, 40, 5], [36, 14, 0, 433]], 'f1_scores': [0.883167042162858, 0.8570813603099441, 0.4232804232804233, 0.8809766022380469]}, 'TOPICS': {'loss': 0.6046, 'accuracy': 0.8589}, 'time': {'elapsed_time': '0:02:02.845483'}}
Testing finished
Saving results..
Results saved
